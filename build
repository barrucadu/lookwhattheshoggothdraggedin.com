#!/usr/bin/env python3

"""build

Usage:
  build [--drafts] [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --drafts        Include draft posts and pages.
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://www.lookwhattheshoggothdraggedin.com/]
"""

import hashlib
import jinja2
import json
import markdown
import shutil
import sys
import yaml

from docopt import docopt
from pathlib import Path

import markdown_extensions

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]
DRAFT_MODE = args["--drafts"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

ABBREVIATIONS = {
    "adnd": {"display": "AD&D", "title": "Advanced Dungeons & Dragons"},
    "bxdnd": {"display": "B/X D&D", "title": "Basic / Expert Dungeons & Dragons"},
    "dnd": {"display": "D&D", "title": "Dungeons & Dragons"},
    "gm": {"display": "GM", "title": "Game Master"},
    "npc": {"display": "NPC", "title": "Non-player Character"},
    "ose": {"display": "OSE", "title": "Old School Essentials"},
    "osr": {"display": "OSR", "title": "Old School Renaissance"},
    "pbta": {"display": "PbtA", "title": "Powered by the Apocalypse"},
    "osric": {
        "display": "OSRIC",
        "title": "Old School Reference and Index Compilation",
    },
    "pc": {"display": "PC", "title": "Player Character"},
    "vtt": {"display": "VTT", "title": "Virtual Tabletop"},
}

SYSTEMS = {
    "call-of-cthulhu": "Call of Cthulhu",
    "dolmenwood": "Dolmenwood",
    "ironsworn": "Ironsworn",
    "ose": "Old School Essentials",
    "rqg": "RuneQuest - Roleplaying in Glorantha",
    "traveller": "Traveller",
    "troika": "Troika!",
}

TOPICS = {
    "campaign-notes": "Campaign Notes",
    "gm-advice": "GM Advice",
    "mechanics": "Mechanics",
    "reviews": "Reviews",
    "scenarios": "Scenarios",
    "setting": "Setting",
}


def do_markdown(text):
    return markdown.markdown(
        text,
        output_format="html5",
        extensions=[
            "admonition",
            "smarty",
            "tables",
            markdown_extensions.AbbreviationExtension(ABBREVIATIONS),
            markdown_extensions.ProbabilityTableExtension(),
            markdown_extensions.RollTableExtension(),
            markdown_extensions.MakeRelativeLinksAbsoluteExtension(BASE_HREF),
        ],
    )


def read_files_from(fdir, permalink_base_href=BASE_HREF, include_drafts=False):
    out = []
    for fpath in Path(fdir).iterdir():
        if not fpath.is_file():
            continue

        lines = fpath.read_text().splitlines()
        metadata_end_idx = lines[1:].index("---") + 1
        text_start_idx = metadata_end_idx + 1
        metadata = yaml.load(
            "\n".join(lines[1:metadata_end_idx]), Loader=yaml.SafeLoader
        )
        if metadata.get("draft", False) and not include_drafts:
            continue
        metadata["text"] = "\n".join(lines[text_start_idx:])
        metadata["body"] = do_markdown(metadata["text"])
        if "slug" not in metadata:
            metadata["slug"] = fpath.stem
        metadata["permalink"] = f"{permalink_base_href}{metadata['slug']}.html"
        out.append(metadata)
    return out


ALL_PAGES = read_files_from("pages", include_drafts=DRAFT_MODE)

ALL_POSTS = sorted(
    read_files_from(
        "posts", permalink_base_href=f"{BASE_HREF}post/", include_drafts=DRAFT_MODE
    ),
    key=lambda post: post["date"],
    reverse=True,
)

ALL_POSTS_EXCLUDING_UNLISTED = [
    post for post in ALL_POSTS if not post.get("unlisted", False)
]

for post in ALL_POSTS:
    if post.get("topic") not in TOPICS:
        print(f"{post['slug']} has invalid topic.")
        sys.exit(1)
    if post.get("system") is not None and post["system"] not in SYSTEMS:
        print(f"{post['slug']} has invalid system.")
        sys.exit(1)

    if "updated" not in post:
        post["updated"] = post["date"]

    post["year"] = post["date"].strftime("%Y")
    post["month"] = post["date"].strftime("%b")
    post["day"] = post["date"].strftime("%-d")
    post["atom_published"] = post["date"].strftime("%Y-%m-%dT%H:%M:%S%zZ")
    post["atom_updated"] = post["updated"].strftime("%Y-%m-%dT%H:%M:%S%zZ")

YEARS = {post["year"]: post["year"] for post in ALL_POSTS_EXCLUDING_UNLISTED}

###############################################################################
# Here be effects

shutil.rmtree(OUT_DIR, ignore_errors=True)
shutil.copytree("static", OUT_DIR)
Path(OUT_DIR, "post").mkdir(exist_ok=True)
Path(OUT_DIR, "system").mkdir()
Path(OUT_DIR, "topic").mkdir()
Path(OUT_DIR, "year").mkdir()

HASHED_LINKS = {}
for fpath in Path("hashed-static").iterdir():
    if not fpath.is_file():
        continue

    file_hash = hashlib.sha256()
    with fpath.open("rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)
    HASHED_LINKS[fpath.name] = (
        f"{fpath.stem}-sha256-{file_hash.hexdigest()}{fpath.suffix}"
    )
    shutil.copy(fpath, Path(OUT_DIR, HASHED_LINKS[fpath.name]))


def find_file_by_slug(directory, slug, default=None):
    for ext in ["png", "jpg"]:
        fname = f"{slug}.{ext}"
        if Path("static", directory, fname).is_file():
            return f"{directory}/{fname}"
    return default


def render(link, template, **metadata):
    slug = link.split("/")[-1].split(".")[0]
    twitter_card = find_file_by_slug("twitter-cards", slug, default="twitter-card.jpg")

    Path(OUT_DIR, link).write_text(
        JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            topics=TOPICS,
            systems=SYSTEMS,
            years=YEARS,
            draft_mode=DRAFT_MODE,
            hashed_links=HASHED_LINKS,
            permalink=f"{BASE_HREF}{link}",
            link=link,
            twitter_card=twitter_card,
            **metadata,
        )
    )


def render_json_feed(link, title, posts):
    Path(OUT_DIR, link).write_text(
        json.dumps(
            {
                "version": "https://jsonfeed.org/version/1.1",
                "title": title,
                "home_page_url": BASE_HREF,
                "feed_url": f"{BASE_HREF}{link}",
                "authors": [
                    {
                        "name": "Michael Walker",
                        "email": "mike@barrucadu.co.uk",
                    },
                ],
                "items": [
                    {
                        "id": post["permalink"],
                        "url": post["permalink"],
                        "content_html": post["body"],
                        "date_published": post["atom_published"],
                        "date_modified": post["atom_updated"],
                    }
                    for post in posts
                ],
            }
        )
    )


def render_feeds_for(link_without_format, title, posts):
    render(
        link_without_format + ".xml",
        "atom.xml",
        title=title,
        posts=posts,
    )
    render_json_feed(
        link_without_format + ".json",
        title=title,
        posts=posts,
    )


render(
    "index.html",
    "archive.html",
    title="Articles",
    posts=ALL_POSTS_EXCLUDING_UNLISTED,
)

render_feeds_for("feed", "Recent Posts", ALL_POSTS_EXCLUDING_UNLISTED)

for field, entries in [("topic", TOPICS), ("system", SYSTEMS), ("year", YEARS)]:
    for slug, name in entries.items():
        matching_posts = [
            post for post in ALL_POSTS_EXCLUDING_UNLISTED if post.get(field) == slug
        ]

        render(
            f"{field}/{slug}.html",
            "archive.html",
            title=name,
            posts=matching_posts,
        )

        render_feeds_for(f"{field}/{slug}", name, matching_posts)

for post in ALL_POSTS:
    render(f"post/{post['slug']}.html", "post.html", title=post["title"], post=post)

for page in ALL_PAGES:
    render(
        f"{page['slug']}.html",
        "page.html",
        title=page["title"],
        page=page,
    )
