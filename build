#!/usr/bin/env python3

"""build

Usage:
  build [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://www.lookwhattheshoggothdraggedin.com/]
"""

import datetime
import jinja2
import json
import markdown
import os
import sys
import yaml
import xml.etree.ElementTree as ET

from distutils import dir_util
from docopt import docopt

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]

FEED_SIZE = 5

JINJA2_ENV = jinja2.Environment(loader=jinja2.FileSystemLoader("_templates"))

with open("config/topics.yaml") as f:
    TOPICS = yaml.safe_load(f)

with open("config/systems.yaml") as f:
    SYSTEMS = yaml.safe_load(f)

with open("config/glossary.yaml") as f:
    GLOSSARY = yaml.safe_load(f)


class GlossaryLinkProcessor(markdown.inlinepatterns.InlineProcessor):
    def handleMatch(self, m, data):
        key = m.group(1)
        item = GLOSSARY[key]

        link = ET.Element("a")
        link.set("href", f"glossary.html#{key}")

        if "abbr" in item:
            abbr = ET.Element("abbr")
            abbr.set("title", item["title"])
            abbr.text = item["abbr"]
            link.append(abbr)
        else:
            link.text = item["title"]

        return link, m.start(0), m.end(0)


class GlossaryLinkExtension(markdown.extensions.Extension):
    def extendMarkdown(self, md):
        md.inlinePatterns.register(GlossaryLinkProcessor(r"\[glo:([a-z]+)\]", md), "glossary", -99999)


def do_markdown(text):
    return markdown.markdown(text, output_format="html5", extensions=["admonition", GlossaryLinkExtension()])


def read_files_from(fdir, permalink_base_href=BASE_HREF):
    out = []
    for fname in os.listdir(fdir):
        fpath = os.path.join(fdir, fname)
        if not os.path.isfile(fpath):
            continue

        with open(fpath, "r") as f:
            lines = f.readlines()
            idx = lines[1:].index("---\n") + 1
            metadata = yaml.load("".join(lines[1:idx]), Loader=yaml.SafeLoader)
            metadata["text"] = "".join(lines[idx + 1:])
            metadata["body"] = do_markdown(metadata["text"])
            if "slug" not in metadata:
                metadata["slug"], _ = os.path.splitext(fname)
            metadata["permalink"] = f"{permalink_base_href}{metadata['slug']}.html"
            out.append(metadata)
    return out


ALL_PAGES = read_files_from("pages")

ALL_POSTS = sorted(
    read_files_from("posts", permalink_base_href=f"{BASE_HREF}post/"),
    key=lambda post: post["date"],
    reverse=True
)

for key, defn in GLOSSARY.items():
    GLOSSARY[key]["body"] = do_markdown(defn["text"])

for post in ALL_POSTS:
    if post.get("topic") not in TOPICS:
        print(f"{post.slug} has invalid topic.")
        sys.exit(1)
    if post.get("system") is not None and post["system"] not in SYSTEMS:
        print(f"{post.slug} has invalid system.")
        sys.exit(1)

    post["year"] = post["date"].strftime("%Y")
    post["month"] = post["date"].strftime("%b")
    post["day"] = post["date"].strftime("%-d")
    post["atom_date"] = post["date"].strftime("%Y-%m-%dT%H:%M:%S%z")

YEARS = { post["year"]: post["year"] for post in ALL_POSTS }

dir_util.copy_tree("static", OUT_DIR)
dir_util.mkpath(os.path.join(OUT_DIR, "post"))
dir_util.mkpath(os.path.join(OUT_DIR, "system"))
dir_util.mkpath(os.path.join(OUT_DIR, "topic"))
dir_util.mkpath(os.path.join(OUT_DIR, "year"))


def render(link, template, **metadata):
    with open(os.path.join(OUT_DIR, link), "w") as f:
        rendered = JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            topics=TOPICS,
            systems=SYSTEMS,
            years=YEARS,
            permalink=f"{BASE_HREF}{link}",
            link=link,
            **metadata,
        )
        print(rendered, file=f)


def render_json_feed(link, title, posts):
    with open(os.path.join(OUT_DIR, link), "w") as f:
        feed = {
            "version": "https://jsonfeed.org/version/1.1",
            "title": title,
            "home_page_url": BASE_HREF,
            "feed_url": f"{BASE_HREF}{link}",
            "authors": [
                {
                    "name": "Michael Walker",
                    "email": "mike@barrucadu.co.uk",
                },
            ],
            "items": [
                {
                    "id": post["permalink"],
                    "url": post["permalink"],
                    "content_text": post["excerpt"],
                    "date_published": post["date"].strftime("%Y-%m-%dT%H:%M:%S%z"),
                }
                for post in posts
            ]
        }

        json.dump(feed, f)


def render_feeds_for(link_without_format, title, posts):
    render(
        link_without_format + ".xml",
        "atom.xml",
        title=title,
        posts=posts[:FEED_SIZE],
    )
    render_json_feed(
        link_without_format + ".json",
        title=title,
        posts=posts[:FEED_SIZE],
    )


render(
    "index.html",
    "archive.html",
    title="Articles",
    posts=ALL_POSTS,
)

render(
    "glossary.html",
    "glossary.html",
    title="Glossary",
    glossary=GLOSSARY,
)

render_feeds_for("feed", "Recent Posts", ALL_POSTS)

for field, entries in [("topic", TOPICS), ("system", SYSTEMS), ("year", YEARS)]:
    for slug, name in entries.items():
        matching_posts = [post for post in ALL_POSTS if post.get(field) == slug]

        render(
            f"{field}/{slug}.html",
            "archive.html",
            title=name,
            posts=matching_posts,
        )

        render_feeds_for(f"{field}/{slug}", name, matching_posts)

for post in ALL_POSTS:
    render(
        f"post/{post['slug']}.html",
        "post.html",
        title=post["title"],
        post=post
    )

for page in ALL_PAGES:
    render(
        f"{page['slug']}.html",
        "page.html",
        title=page["title"],
        page=page,
    )
