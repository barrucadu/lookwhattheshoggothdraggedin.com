#!/usr/bin/env python3

"""build

Usage:
  build [--drafts] [--out=<dir>] [--root=<url>]
  build (-h | --help)

Options:
  -h --help       Show this screen.
  --drafts        Include draft posts and pages.
  --out=<dir>     Directory to generate site in [default: _site]
  --root=<url>    Root of the website [default: https://www.lookwhattheshoggothdraggedin.com/]
"""

import datetime
import hashlib
import jinja2
import json
import markdown
import os
import sys
import xml.etree.ElementTree as ET
import yaml

from distutils import dir_util, file_util
from docopt import docopt

args = docopt(__doc__)
OUT_DIR = args["--out"]
BASE_HREF = args["--root"]
DRAFT_MODE = args["--drafts"]

JINJA2_ENV = jinja2.Environment(
    autoescape=jinja2.select_autoescape(["html", "xml"]),
    loader=jinja2.FileSystemLoader("_templates"),
)

with open("config/topics.yaml") as f:
    TOPICS = yaml.safe_load(f)

with open("config/systems.yaml") as f:
    SYSTEMS = yaml.safe_load(f)

with open("config/glossary.yaml") as f:
    GLOSSARY = yaml.safe_load(f)


class GlossaryLinkProcessor(markdown.inlinepatterns.InlineProcessor):
    def handleMatch(self, m, data):
        global GLOSSARY_CACHE

        is_plural = m.group(1) == "s"
        key = m.group(2)
        override_title = m.group(4)
        item = GLOSSARY[key]

        el = ET.Element("a")
        el.set("class", "link--glossary")
        el.set("href", f"glossary.html#{key}")

        title = item.get("title_plural", item["title"] + "s") if is_plural else item["title"]

        if "abbr" in item and item.get("use_abbr_for_glo_link", True) and override_title is None:
            abbr = ET.Element("abbr")
            abbr.set("title", title)
            abbr.text = item.get("abbr_plural", item["abbr"] + "s") if is_plural else item["abbr"]
            el.append(abbr)
        else:
            el.text = override_title or title

        return el, m.start(0), m.end(0)


class GlossaryLinkExtension(markdown.extensions.Extension):
    def extendMarkdown(self, md):
        md.inlinePatterns.register(GlossaryLinkProcessor(r"\[glo(s)?:([a-z-]+)(\s*\"([^\"]+)\")?\]", md), "glossary", -99999)


def do_markdown(text):
    return markdown.markdown(text, output_format="html5", extensions=["admonition", "smarty", GlossaryLinkExtension()])


def read_files_from(fdir, permalink_base_href=BASE_HREF, include_drafts=False):
    out = []
    for fname in os.listdir(fdir):
        fpath = os.path.join(fdir, fname)
        if not os.path.isfile(fpath):
            continue

        with open(fpath, "r") as f:
            lines = f.readlines()
            idx = lines[1:].index("---\n") + 1
            metadata = yaml.load("".join(lines[1:idx]), Loader=yaml.SafeLoader)
            if metadata.get("draft", False) and not include_drafts:
                continue
            metadata["text"] = "".join(lines[idx + 1:])
            metadata["body"] = do_markdown(metadata["text"])
            if "slug" not in metadata:
                metadata["slug"], _ = os.path.splitext(fname)
            metadata["permalink"] = f"{permalink_base_href}{metadata['slug']}.html"
            out.append(metadata)
    return out


ALL_PAGES = read_files_from("pages", include_drafts=DRAFT_MODE)

ALL_POSTS = sorted(
    read_files_from("posts", permalink_base_href=f"{BASE_HREF}post/", include_drafts=DRAFT_MODE),
    key=lambda post: post["date"],
    reverse=True
)

for key, defn in GLOSSARY.items():
    GLOSSARY[key]["body"] = do_markdown(defn["text"])

for post in ALL_POSTS:
    if post.get("topic") not in TOPICS:
        print(f"{post['slug']} has invalid topic.")
        sys.exit(1)
    if post.get("system") is not None and post["system"] not in SYSTEMS:
        print(f"{post['slug']} has invalid system.")
        sys.exit(1)

    post["year"] = post["date"].strftime("%Y")
    post["month"] = post["date"].strftime("%b")
    post["day"] = post["date"].strftime("%-d")
    post["atom_date"] = post["date"].strftime("%Y-%m-%dT%H:%M:%S%z")
    post["excerpt"] = do_markdown(post["excerpt"])

YEARS = { post["year"]: post["year"] for post in ALL_POSTS }

dir_util.copy_tree("static", OUT_DIR)
dir_util.mkpath(os.path.join(OUT_DIR, "post"))
dir_util.mkpath(os.path.join(OUT_DIR, "system"))
dir_util.mkpath(os.path.join(OUT_DIR, "topic"))
dir_util.mkpath(os.path.join(OUT_DIR, "year"))

HASHED_LINKS = {}
for fname in os.listdir("hashed-static"):
    fpath = os.path.join("hashed-static", fname)
    if not os.path.isfile(fpath):
        continue

    file_hash = hashlib.sha256()
    with open(fpath, "rb") as f:
        while True:
            data = f.read(65536)
            if not data:
                break
            file_hash.update(data)
    base, ext = os.path.splitext(fname)
    HASHED_LINKS[fname] = f"{base}-sha256-{file_hash.hexdigest()}{ext}"
    file_util.copy_file(fpath, os.path.join(OUT_DIR, HASHED_LINKS[fname]))


def render(link, template, **metadata):
    slug = link.split("/")[-1].split(".")[0]
    if os.path.isfile(os.path.join("static", "twitter-cards", slug + ".png")):
        twitter_card = f"twitter-cards/{slug}.png"
    elif os.path.isfile(os.path.join("static", "twitter-cards", slug + ".jpg")):
        twitter_card = f"twitter-cards/{slug}.jpg"
    else:
        twitter_card = "twitter-card.png"

    with open(os.path.join(OUT_DIR, link), "w") as f:
        rendered = JINJA2_ENV.get_template(template).render(
            base_href=BASE_HREF,
            topics=TOPICS,
            systems=SYSTEMS,
            years=YEARS,
            draft_mode=DRAFT_MODE,
            hashed_links=HASHED_LINKS,
            permalink=f"{BASE_HREF}{link}",
            link=link,
            twitter_card=twitter_card,
            **metadata,
        )
        print(rendered, file=f)


def render_json_feed(link, title, posts):
    with open(os.path.join(OUT_DIR, link), "w") as f:
        feed = {
            "version": "https://jsonfeed.org/version/1.1",
            "title": title,
            "home_page_url": BASE_HREF,
            "feed_url": f"{BASE_HREF}{link}",
            "authors": [
                {
                    "name": "Michael Walker",
                    "email": "mike@barrucadu.co.uk",
                },
            ],
            "items": [
                {
                    "id": post["permalink"],
                    "url": post["permalink"],
                    "content_text": post["excerpt"],
                    "date_published": post["date"].strftime("%Y-%m-%dT%H:%M:%S%z"),
                }
                for post in posts
            ]
        }

        json.dump(feed, f)


def render_feeds_for(link_without_format, title, posts):
    render(
        link_without_format + ".xml",
        "atom.xml",
        title=title,
        posts=posts,
    )
    render_json_feed(
        link_without_format + ".json",
        title=title,
        posts=posts,
    )


render(
    "index.html",
    "archive.html",
    title="Articles",
    posts=ALL_POSTS,
)

render(
    "glossary.html",
    "glossary.html",
    title="Glossary",
    glossary=GLOSSARY,
)

render_feeds_for("feed", "Recent Posts", ALL_POSTS)

for field, entries in [("topic", TOPICS), ("system", SYSTEMS), ("year", YEARS)]:
    for slug, name in entries.items():
        matching_posts = [post for post in ALL_POSTS if post.get(field) == slug]

        render(
            f"{field}/{slug}.html",
            "archive.html",
            title=name,
            posts=matching_posts,
        )

        render_feeds_for(f"{field}/{slug}", name, matching_posts)

for post in ALL_POSTS:
    render(
        f"post/{post['slug']}.html",
        "post.html",
        title=post["title"],
        post=post
    )

for page in ALL_PAGES:
    render(
        f"{page['slug']}.html",
        "page.html",
        title=page["title"],
        page=page,
    )
